{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41ec664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\STORM\n",
      "[nltk_data]     Tech\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\STORM\n",
      "[nltk_data]     Tech\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\STORM\n",
      "[nltk_data]     Tech\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "security - 0.5244044240850758\n",
      "protocol - 0.28603877677367767\n",
      "access - 0.2383656473113981\n",
      "visitor - 0.19069251784911848\n",
      "biometric - 0.14301938838683884\n",
      "information - 0.14301938838683884\n",
      "must - 0.14301938838683884\n",
      "new - 0.14301938838683884\n",
      "office - 0.14301938838683884\n",
      "please - 0.14301938838683884\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens if word.isalpha() and word.lower() not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Example document\n",
    "document = \"\"\"\n",
    "**Confidential Memo**\n",
    "\n",
    "---\n",
    "\n",
    "To: All Department Heads\n",
    "\n",
    "From: Office of Administration\n",
    "\n",
    "Date: April 26, 2024\n",
    "\n",
    "Subject: Implementation of New Security Protocol\n",
    "\n",
    "---\n",
    "\n",
    "Dear Department Heads,\n",
    "\n",
    "We are writing to inform you of the upcoming implementation of a new security protocol aimed at enhancing the safety and confidentiality of our organization's sensitive information. This protocol will be effective starting May 1, 2024.\n",
    "\n",
    "Key Points of the Protocol:\n",
    "\n",
    "1. **Biometric Access Control**: Access to designated secure areas will now require biometric authentication in addition to traditional keycard access. Please ensure that all employees requiring access to these areas are registered in the biometric system by April 30, 2024.\n",
    "\n",
    "2. **Encryption Policy**: All electronic communication containing sensitive information must be encrypted using the latest encryption standards. This includes emails, file transfers, and instant messages. Failure to comply may result in disciplinary action.\n",
    "\n",
    "3. **Visitor Protocol**: A stricter visitor registration process will be implemented. All visitors must be pre-approved and escorted at all times while on the premises. Visitor access will be restricted to designated areas only.\n",
    "\n",
    "4. **Security Awareness Training**: Mandatory security awareness training sessions will be conducted for all employees. These sessions will cover topics such as recognizing phishing attempts, password security, and physical security best practices.\n",
    "\n",
    "5. **Incident Reporting**: Any security incidents or breaches must be reported immediately to the IT Security team. Prompt reporting is crucial for mitigating potential risks and minimizing the impact of security incidents.\n",
    "\n",
    "Please disseminate this information to all staff members within your respective departments and ensure full compliance with the new security protocol. We appreciate your cooperation in maintaining the security and integrity of our organization's operations.\n",
    "\n",
    "Should you have any questions or require further clarification, please do not hesitate to contact the Office of Administration.\n",
    "\n",
    "Sincerely,\n",
    "\n",
    "[Signature]\n",
    "\n",
    "Office of Administration\n",
    "\"\"\"\n",
    "def getKeywords(doc):\n",
    "    # Preprocess the document\n",
    "    preprocessed_doc = preprocess_text(doc)\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([preprocessed_doc])\n",
    "\n",
    "    # Get feature names (words)\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Get TF-IDF scores for each word\n",
    "    tfidf_scores = tfidf_matrix.toarray()[0]\n",
    "\n",
    "    # Sort words by their TF-IDF scores\n",
    "    keywords = [(feature_names[i], tfidf_scores[i]) for i in tfidf_scores.argsort()[::-1]]\n",
    "\n",
    "    # Print top keywords\n",
    "    return keywords\n",
    "\n",
    "keywords = getKeywords(document)\n",
    "\n",
    "top_keywords = 10\n",
    "for keyword, score in keywords[:top_keywords]:\n",
    "    print(keyword, \"-\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348c6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('secure', 3.0043031950763393), ('Digital', 1.7573857407628375), ('mail', 1.4642101860308727), ('banana', -0.10331752296194005)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Load the spaCy model with word embeddings\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def find_matching_tags(keywords, tags):\n",
    "    tag_scores = {tag: 0 for tag in tags}\n",
    "\n",
    "    # Calculate relevance score for each tag based on semantic similarity\n",
    "    for keyword, score in keywords:\n",
    "        keyword_embedding = nlp(keyword).vector\n",
    "        for tag in tags:\n",
    "            tag_embedding = nlp(tag).vector\n",
    "            similarity_score = keyword_embedding.dot(tag_embedding) / (norm(keyword_embedding) * norm(tag_embedding))\n",
    "            tag_scores[tag] += similarity_score * score\n",
    "    \n",
    "    # Sort tags by relevance score\n",
    "    sorted_tags = sorted(tag_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_tags\n",
    "\n",
    "# Example usage:\n",
    "tags = [\"mail\", \"secure\", \"Digital\", \"banana\"]\n",
    "\n",
    "matching_tags = find_matching_tags(keywords, tags)\n",
    "print(matching_tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
